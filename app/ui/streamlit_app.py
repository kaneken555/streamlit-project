import streamlit as st
from typing import List
from app.core.types import Message
from app.services.chat_orchestrator import ChatOrchestrator
from app.registry.providers import build_stack
from app.config.settings import settings

st.set_page_config(page_title="Chat + RAG", page_icon="ğŸ¦™", layout="centered")
st.title("ğŸ¦™ Ollama Ã— Streamlitï¼ˆæ—¥æœ¬èªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ + RAGï¼‰")

# ä¼šè©±ãƒ¡ãƒ¢ãƒªï¼ˆUIå±¤ã§ã¯ dict ã§ä¿æŒ â†’ å‘¼ã¶ç›´å‰ã« Message åŒ–ã§ã‚‚OKï¼‰
if "messages" not in st.session_state:
    st.session_state.messages = []
if "model" not in st.session_state:
    st.session_state.model = settings.default_model

def to_messages_dicts_to_Message(lst: List[dict]) -> List[Message]:
    return [Message(role=m["role"], content=m["content"]) for m in lst]

def truncated_history(messages: List[dict], max_rounds: int):
    if len(messages) <= max_rounds * 2:
        return messages
    return messages[-max_rounds * 2:]

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("âš™ï¸ è¨­å®šï¼ˆOllamaï¼‰")
    base_url = st.text_input("Ollama URL", value=settings.ollama_url, help="ä¾‹: http://localhost:11434")

    # Providerã¨Retrieverã‚’æ§‹ç¯‰ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰
    @st.cache_resource(show_spinner=False)
    def get_stack(url: str):
        llm, retriever = build_stack("ollama", base_url=url, embed_model=settings.embed_model, chroma_path=settings.chroma_path)
        return llm, retriever

    llm, retriever = get_stack(base_url)

    try:
        models = llm.list_models()
    except Exception:
        models = []

    if models:
        init_idx = models.index(st.session_state.model) if st.session_state.model in models else 0
        model = st.selectbox("ãƒ¢ãƒ‡ãƒ«å", models, index=init_idx)
    else:
        st.info("ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚æ‰‹å…¥åŠ›ã§æŒ‡å®šã§ãã¾ã™ã€‚")
        model = st.text_input("ãƒ¢ãƒ‡ãƒ«åï¼ˆæ‰‹å…¥åŠ›ï¼‰", value=st.session_state.model)

    st.session_state.model = model

    temperature = st.slider("æ¸©åº¦ (å‰µé€ æ€§)", 0.0, 1.0, settings.temperature, 0.1)
    num_ctx = st.number_input("ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•· (num_ctx)", 2048, 32768, settings.num_ctx, 1024)

    system_prompt = st.text_area(
        "ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
        value=("ã‚ãªãŸã¯æ—¥æœ¬èªã§ä¸å¯§ã‹ã¤ã‚ã‹ã‚Šã‚„ã™ãå›ç­”ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\n"
               "å¿…ãšæ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚è‹±èªã§å‡ºåŠ›ã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚\n"
               "å°‚é–€ç”¨èªãŒå‡ºã‚‹å ´åˆã¯æ—¥æœ¬èªã®è£œè¶³ã‚‚æ·»ãˆã¦ãã ã•ã„ã€‚\n"
               "éåº¦ã«é•·ãã›ãšã€è¦‹å‡ºã—ã‚„ç®‡æ¡æ›¸ãã‚’é©åˆ‡ã«ä½¿ã£ã¦æ•´ç†ã—ã¦ãã ã•ã„ã€‚"),
        height=140,
    )

    max_history = st.number_input("å±¥æ­´ä¸Šé™ï¼ˆå¾€å¾©æ•°ï¼‰", 2, 50, 10, 1)

    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ§¹ å±¥æ­´ã‚¯ãƒªã‚¢"):
            st.session_state.messages = []
            st.rerun()
    with col2:
        st.caption("Dockerâ†’ãƒã‚¤ãƒ†ã‚£ãƒ–Ollama: http://host.docker.internal:11434")

# æ—¢å­˜å±¥æ­´ã®æç”»
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ï¼ˆæ¯å›å†ç”Ÿæˆã§ã‚‚è»½ã„ï¼‰
orch = ChatOrchestrator(llm=llm, retriever=retriever, base_system_prompt=system_prompt)

# å…¥åŠ›å—ä»˜
if user_input := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›â€¦"):
    user_input = user_input.strip()

    st.session_state.messages.append({"role": "user", "content": user_input})
    st.session_state.messages = truncated_history(st.session_state.messages, max_history)

    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        stream, sources = orch.run_stream(
            user_input=user_input,
            history=to_messages_dicts_to_Message([m for m in st.session_state.messages if m["role"] in ("user","assistant")]),
            model=st.session_state.model,
            options={"temperature": float(temperature), "num_ctx": int(num_ctx)},
            top_k=4,
        )
        # Streamlit ã® write_stream ã¯ãƒ†ã‚­ã‚¹ãƒˆã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚‹
        reply = st.write_stream((chunk.content for chunk in stream))

    st.session_state.messages.append({"role": "assistant", "content": reply})

    if sources:
        st.caption("å‡ºå…¸: " + " | ".join(sources))
